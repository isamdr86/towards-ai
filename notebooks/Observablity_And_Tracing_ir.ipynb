{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isamdr86/towards-ai/blob/main/notebooks/Observablity_And_Tracing_ir.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Dependencies"
      ],
      "metadata": {
        "id": "AItauLdsp7jj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pmnledOoOjbn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21806ca7-92ea-4247-f808-685665c4296d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/49.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "pip install langchain-openai==0.2.3 langchain==0.3.4 --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U langchain langchain-openai"
      ],
      "metadata": {
        "id": "RUAZOpyualLz",
        "outputId": "1eeca159-e0b0-46b7-c14e-948424945a97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.4)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.3.15-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.11/dist-packages (0.2.3)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.1-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.11)\n",
            "Collecting langchain-core<0.4.0,>=0.3.31 (from langchain)\n",
            "  Downloading langchain_core-0.3.31-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.5)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.1.147)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.5)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
            "Collecting openai<2.0.0,>=1.58.1 (from langchain-openai)\n",
            "  Downloading openai-1.59.9-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.31->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.31->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.31->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.14)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.8.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.31->langchain) (3.0.0)\n",
            "Downloading langchain-0.3.15-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.3.1-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.3/54.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.31-py3-none-any.whl (412 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.2/412.2 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.59.9-py3-none-any.whl (455 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m455.5/455.5 kB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai, langchain-core, langchain-openai, langchain\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.55.3\n",
            "    Uninstalling openai-1.55.3:\n",
            "      Successfully uninstalled openai-1.55.3\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.29\n",
            "    Uninstalling langchain-core-0.3.29:\n",
            "      Successfully uninstalled langchain-core-0.3.29\n",
            "  Attempting uninstall: langchain-openai\n",
            "    Found existing installation: langchain-openai 0.2.3\n",
            "    Uninstalling langchain-openai-0.2.3:\n",
            "      Successfully uninstalled langchain-openai-0.2.3\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.4\n",
            "    Uninstalling langchain-0.3.4:\n",
            "      Successfully uninstalled langchain-0.3.4\n",
            "Successfully installed langchain-0.3.15 langchain-core-0.3.31 langchain-openai-0.3.1 openai-1.59.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install openai==1.55.3 httpx==0.27.2 tiktoken==0.7.0 --force-reinstall"
      ],
      "metadata": {
        "id": "Gz4IGRM7X7f7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LANGSMITH_TRACING=\"true\"\n",
        "LANGSMITH_ENDPOINT=\"https://api.smith.langchain.com\"\n",
        "LANGSMITH_API_KEY=\"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\"\n",
        "LANGSMITH_PROJECT=\"towardsaiproj\"\n",
        "OPENAI_API_KEY=userdata.get('openai_api_key')"
      ],
      "metadata": {
        "id": "k4EXTMsCas7t"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"LANGCHAIN_API_KEY\"] = LANGSMITH_API_KEY\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = LANGSMITH_PROJECT"
      ],
      "metadata": {
        "id": "eL52wKQPbE4K"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI()\n",
        "llm.invoke(\"Hello, world!\")"
      ],
      "metadata": {
        "id": "A9EI3Ozoa1oY",
        "outputId": "37b2993f-3a73-498b-84d3-5787ea5e2313",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langsmith.client:Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Forbidden\"}')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Hello there! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 11, 'total_tokens': 22, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-8feed066-0e80-4ced-84a0-e303ab3a819b-0', usage_metadata={'input_tokens': 11, 'output_tokens': 11, 'total_tokens': 22, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up env"
      ],
      "metadata": {
        "id": "AgSc92W9qIeF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('openai_api_key')\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get('langchain_api_key')\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"towardsai\""
      ],
      "metadata": {
        "id": "lXz2mUoyiEuJ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tracing Langchain calls"
      ],
      "metadata": {
        "id": "LAgKNo9kqOZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain import hub\n",
        "\n",
        "prompt = hub.pull(\"wikianes/section_writer\")\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "\n",
        "chain = prompt | llm\n",
        "output = chain.invoke({\"section_description\": \"Quantum Physics\"})\n",
        "print(output.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okLDL4YQhljS",
        "outputId": "50d875e8-0d1c-4f96-9aac-79fc740c9022"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langsmith.client:Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Forbidden\"}')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Quantum Physics in Anesthesia\n",
            "\n",
            "## Overview of Quantum Physics\n",
            "\n",
            "Quantum physics, the study of matter and energy at the smallest scales, has revolutionized our understanding of the universe. While primarily a branch of theoretical and experimental physics, its principles have begun to influence various fields, including medicine and anesthesiology. Understanding quantum concepts can enhance the anesthesiologist's approach to drug interactions, monitoring techniques, and the fundamental understanding of consciousness.\n",
            "\n",
            "## Implications for Anesthetic Agents\n",
            "\n",
            "### Mechanistic Insights\n",
            "\n",
            "The behavior of anesthetic agents at the molecular level can be analyzed through quantum physics principles. Quantum tunneling, for example, explains how anesthetic molecules can interact with neuronal receptors, leading to altered consciousness and analgesia. This insight can guide anesthesiologists in selecting appropriate agents based on their quantum characteristics, such as binding affinity and molecular weight.\n",
            "\n",
            "### Drug Interaction\n",
            "\n",
            "Quantum mechanics also provides a framework for understanding the interactions between anesthetic drugs and their targets. The principles of quantum entanglement and superposition may explain how certain anesthetics can produce synergistic effects when used in combination, ultimately influencing dosing strategies in the perioperative setting.\n",
            "\n",
            "## Monitoring Techniques\n",
            "\n",
            "### Advanced Imaging\n",
            "\n",
            "Innovations in imaging technologies, such as functional MRI (fMRI) and quantum dot imaging, have been instrumental in preoperative assessment. These techniques utilize quantum effects to provide real-time insights into brain activity and perfusion changes during anesthesia. Anesthesiologists can leverage this information to better tailor anesthetic plans that consider individual patient responses.\n",
            "\n",
            "### Quantum Sensors\n",
            "\n",
            "The development of quantum sensors, which utilize quantum phenomena for enhanced sensitivity, has potential applications in monitoring anesthetic depth and physiological changes. These sensors can provide precise measurements of brain activity, enabling anesthesiologists to optimize anesthetic delivery and minimize complications.\n",
            "\n",
            "## Consciousness and Anesthesia\n",
            "\n",
            "### Quantum Consciousness Theories\n",
            "\n",
            "Emerging theories propose that consciousness may be tied to quantum processes within the brain. While these theories remain speculative, they prompt anesthesiologists to consider the implications of anesthetic depth and patient awareness. Understanding the potential quantum basis of consciousness may influence how anesthesiologists approach sedation and monitor patients' awareness during procedures.\n",
            "\n",
            "### Ethical Considerations\n",
            "\n",
            "As our understanding of consciousness continues to evolve, anesthesiologists must remain vigilant about ethical considerations surrounding patient awareness during anesthesia. Engaging with quantum theories may encourage discussions about informed consent and the potential for patients to experience awareness during anesthesia, even in a deeply sedated state.\n",
            "\n",
            "## Conclusion\n",
            "\n",
            "While the direct application of quantum physics in anesthesiology is still developing, its principles offer valuable insights into the molecular mechanisms of anesthetic action, innovative monitoring techniques, and emerging theories of consciousness. Anesthesiologists who stay informed about these advancements may enhance their practice and improve patient outcomes in the surgical setting.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langsmith.client:Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Forbidden\"}')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tracing OpenAI calls"
      ],
      "metadata": {
        "id": "0-s3VBrSzkXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from langsmith.wrappers import wrap_openai\n",
        "\n",
        "# wrap_openai from langsmith provides wrapper to\n",
        "ai_client = wrap_openai(OpenAI())\n",
        "\n",
        "\n",
        "def retrieve_documents(inquiry: str):\n",
        "    docs = [\n",
        "        \"Vector databases enable efficient semantic search for LLMs.\",\n",
        "        \"Retrieval-Augmented Generation (RAG) improves LLM accuracy with relevant context.\",\n",
        "        \"Large Language Models (LLMs) have set new benchmarks in NLP tasks.\",\n",
        "        \"Transformer architectures have revolutionized many areas of machine learning.\",\n",
        "        \"Embedding models convert text into vector representations for similarity comparisons.\"\n",
        "    ]\n",
        "    return docs\n",
        "\n",
        "def ask_qa(query):\n",
        "    context = retrieve_documents(query)\n",
        "    system_prompt = f\"\"\"\n",
        "    You are an assistant for question-answering tasks.\n",
        "    Use the following pieces of retrieved context to answer the question.\n",
        "    Context: {context}\n",
        "    \"\"\"\n",
        "\n",
        "    return ai_client.chat.completions.create(\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": query},\n",
        "        ],\n",
        "        model=\"gpt-4o-mini\",\n",
        "    )"
      ],
      "metadata": {
        "id": "1sM6lLW2sFT-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ask_qa(\"what is vector db?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_sGUKNusXcA",
        "outputId": "611d15dd-9773-4d25-8ed7-1b7d1d3736a9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langsmith.client:Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Forbidden\"}')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatCompletion(id='chatcmpl-AsA42GtNf91GpQUoBfd3PND9kzwqn', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='A vector database is a specialized type of database designed to store and manage vector representations of data, which are typically used in machine learning and natural language processing tasks. These vectors enable efficient semantic search by allowing for similarity comparisons between data points, making it easier to retrieve relevant information based on context. Vector databases enhance the performance of Large Language Models (LLMs) and other applications by supporting fast searches through high-dimensional data spaces.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1737471762, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_72ed7ab54c', usage=CompletionUsage(completion_tokens=85, prompt_tokens=116, total_tokens=201, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langsmith.client:Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Forbidden\"}')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Langsmith traceable decorator"
      ],
      "metadata": {
        "id": "-2Inyx_2FPuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from langsmith import traceable\n",
        "\n",
        "openai_client = OpenAI()\n",
        "\n",
        "@traceable(run_type=\"llm\", name=\"OpenAI call\")\n",
        "def call_llm(model, messages):\n",
        "    result = openai_client.chat.completions.create(\n",
        "            messages=messages,\n",
        "            model=model\n",
        "        )\n",
        "    return result.choices[0].message.content\n",
        "\n",
        "\n",
        "@traceable(run_type=\"retriever\")\n",
        "def retrieve_documents(inquiry: str):\n",
        "    docs = [\n",
        "        \"Vector databases enable efficient semantic search for LLMs.\",\n",
        "        \"Retrieval-Augmented Generation (RAG) improves LLM accuracy with relevant context.\",\n",
        "        \"Large Language Models (LLMs) have set new benchmarks in NLP tasks.\",\n",
        "        \"Transformer architectures have revolutionized many areas of machine learning.\",\n",
        "        \"Embedding models convert text into vector representations for similarity comparisons.\"\n",
        "    ]\n",
        "    return docs\n",
        "\n",
        "@traceable(run_type=\"chain\")\n",
        "def ask_qa(query):\n",
        "    context = retrieve_documents(query)\n",
        "    system_prompt = f\"\"\"\n",
        "    You are an assistant for question-answering tasks.\n",
        "    Use the following pieces of retrieved context to answer the question.\n",
        "    Context: {context}\n",
        "    \"\"\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": query},\n",
        "    ]\n",
        "    return call_llm(\"gpt-4o-mini\", messages)"
      ],
      "metadata": {
        "id": "wzkrlI7Hsa54"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ask_qa(\"What are large language models\", langsmith_extra={\"metadata\": {\"user\": \"test_user@gmail.com\"}})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "IvUZtIjFFmyB",
        "outputId": "f52acfad-bdfd-4048-f98f-b3e0b7e55b47"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langsmith.client:Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Forbidden\"}')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Large Language Models (LLMs) are advanced AI models designed to understand and generate human-like text. They are based on transformer architectures, which have revolutionized various areas of machine learning, particularly in natural language processing (NLP) tasks. LLMs are capable of performing a range of language tasks, such as translation, summarization, question-answering, and more, and they have set new benchmarks for performance in these areas. They often utilize techniques like Retrieval-Augmented Generation (RAG) to enhance their accuracy by incorporating relevant contextual information.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langsmith.client:Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Forbidden\"}')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sjEzBXy8aGdy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}