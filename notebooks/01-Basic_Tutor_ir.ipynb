{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isamdr86/towards-ai/blob/main/notebooks/01-Basic_Tutor_ir.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epk7eWiPkUYM"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/towardsai/ai-tutor-rag-system/blob/main/notebooks/01-Basic_Tutor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMXyyXD0xix9"
      },
      "source": [
        "# Install Packages and Setup Variables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4Q0N2omkAoZ",
        "outputId": "f3ceed09-47e3-4086-ad57-f28f475f9e7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.6/389.6 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.0/345.0 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.8/431.8 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.9/164.9 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jupyter-server 1.24.0 requires anyio<4,>=3.1.0, but you have anyio 4.7.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install openai==1.55.3 httpx==0.27.2 --force-reinstall --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xxK7EAAvr2aT"
      },
      "outputs": [],
      "source": [
        "# Set the following API Keys in the Python environment. Will be used later.\n",
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('openai_api_key')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68RbStS-xpbL"
      },
      "source": [
        "# Load the API client\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "La8hdWqJkFkh"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "# Defining the \"client\" object that enables\n",
        "# us to connect to OpenAI API endpoints.\n",
        "client = OpenAI()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CC-sa_uv6J2C"
      },
      "source": [
        "# Query the API\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7JRrn0uIsBfg"
      },
      "outputs": [],
      "source": [
        "# Define two questions: 1) Related to AI, 2) Unrelated topic.\n",
        "# These questions will be used to evaluate model's performance.\n",
        "QUESTION_AI = \"List a number of famous artificial intelligence frameworks?\"\n",
        "QUESTION_NOT_AI = (\n",
        "    \"What is the name of the highest mountain in the world and its height?\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ** learning note **:\n",
        "\n",
        "the messages can have three different roles:\n",
        "- 'system' for setting the guidelines for the model\n",
        "- 'user' for the prompts and questions from the end-user\n",
        "- 'assistant' for the AI model's replies"
      ],
      "metadata": {
        "id": "sibrjCkSkyLZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CcP26IauuBuV"
      },
      "outputs": [],
      "source": [
        "# Defining a function to answer a question using \"gpt-4o-mini\" model.\n",
        "def ask_ai_tutor(question):\n",
        "    try:\n",
        "        # Formulating the system prompt and condition the model to answer only AI-related questions.\n",
        "        system_prompt = (\n",
        "            \"You are an AI tutor specialized in answering artificial intelligence-related questions. \"\n",
        "            \"Only answer AI-related question, else say that you cannot answer this question.\"\n",
        "        )\n",
        "\n",
        "        # Create a user prompt with the user's question\n",
        "        prompt = f\"Please provide an informative and accurate answer to the following question.\\nQuestion: {question}\\nAnswer:\"\n",
        "\n",
        "        # Call the OpenAI API\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            temperature=0,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_prompt},\n",
        "                {\"role\": \"user\", \"content\": prompt},\n",
        "            ],\n",
        "        )\n",
        "\n",
        "        # Return the AI's response\n",
        "        return response.choices[0].message.content.strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {e}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_dbwURpufR7",
        "outputId": "8eed8862-74fc-47c8-dcc2-ce343237fa24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Some famous artificial intelligence frameworks include:\n",
            "\n",
            "1. **TensorFlow**: An open-source library developed by Google for numerical computation and machine learning, widely used for deep learning applications.\n",
            "\n",
            "2. **PyTorch**: An open-source machine learning library developed by Facebook's AI Research lab, known for its flexibility and ease of use, particularly in research.\n",
            "\n",
            "3. **Keras**: A high-level neural networks API, written in Python and capable of running on top of TensorFlow, Theano, or Microsoft Cognitive Toolkit (CNTK).\n",
            "\n",
            "4. **Scikit-learn**: A Python library for machine learning that provides simple and efficient tools for data mining and data analysis, built on NumPy, SciPy, and Matplotlib.\n",
            "\n",
            "5. **Caffe**: A deep learning framework made with expression, speed, and modularity in mind, developed by the Berkeley Vision and Learning Center (BVLC).\n",
            "\n",
            "6. **MXNet**: A flexible and efficient deep learning framework that supports both symbolic and imperative programming, developed by Apache.\n",
            "\n",
            "7. **Chainer**: A Python-based deep learning framework that allows for dynamic computation graphs, making it easier to work with complex architectures.\n",
            "\n",
            "8. **Fastai**: A library built on top of PyTorch that simplifies training neural networks and provides high-level components for building models quickly.\n",
            "\n",
            "These frameworks are widely used in both academic research and industry applications for developing AI models and solutions.\n"
          ]
        }
      ],
      "source": [
        "# Ask the AI-related question.\n",
        "RES_AI = ask_ai_tutor(QUESTION_AI)\n",
        "print(RES_AI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37YuVJQquhpN",
        "outputId": "e4a67ced-fa90-45c0-a80d-bdd1b500d819"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I cannot answer this question.\n"
          ]
        }
      ],
      "source": [
        "# Ask the unrelated question.\n",
        "RES_NOT_AI = ask_ai_tutor(QUESTION_NOT_AI)\n",
        "print(RES_NOT_AI)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRBgk6WToIK0"
      },
      "source": [
        "# History\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_6GN2XsoEyM",
        "outputId": "20f63c58-8659-4816-fbf2-300bdff842fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow is an open-source machine learning framework developed by Google that facilitates numerical computation and deep learning. It provides a comprehensive ecosystem of tools, libraries, and community resources that enable researchers and developers to build and deploy machine learning models efficiently. TensorFlow supports a variety of tasks, including neural network training and inference, and is designed to run on multiple platforms, including CPUs, GPUs, and TPUs. Its flexible architecture allows for easy model building and experimentation, making it a popular choice for both academic research and production environments. TensorFlow also includes high-level APIs like Keras for simplified model development.\n"
          ]
        }
      ],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    temperature=0,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are an AI tutor specialized in answering artificial intelligence-related questions. Only answer AI-related question, else say that you cannot answer this question.\",\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"Please provide an informative and accurate answer to the following question.\\nQuestion: {QUESTION_AI}\\nAnswer:\",\n",
        "        },\n",
        "        {\"role\": \"assistant\", \"content\": RES_AI},\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"Please provide an informative and accurate answer to the following question.\\nQuestion: {QUESTION_NOT_AI}\\nAnswer:\",\n",
        "        },\n",
        "        {\"role\": \"assistant\", \"content\": RES_NOT_AI},\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Please provide an informative and accurate answer to the following question.\\nQuestion: Can you write a summary of the first suggested AI framework in the first question?\\nAnswer:\",\n",
        "        },\n",
        "    ],\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content.strip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKCXmzLVxt51"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}